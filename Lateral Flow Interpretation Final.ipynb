{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "from datetime import datetime\n",
    "from datetime import date \n",
    "from datetime import time\n",
    "import cv2\n",
    "import glob\n",
    "import os \n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas  as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import SimpleITK as sitk\n",
    "from torchsummary import summary\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.utils import shuffle\n",
    "import skimage\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import datasets,transforms, models\n",
    "import torchvision.transforms.functional as TF\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions & Dataset Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset and loaded images for segmentation models training\n",
    "class SegDataset(Dataset):\n",
    "    def __init__(self, filename_slices, transform):\n",
    "        super().__init__()\n",
    "        self._filename_slices = filename_slices \n",
    "        self._transform = transform    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Read in the image\n",
    "        label_path,label_img,gt_path,gt_img,idx = self._filename_slices[index]\n",
    "        mm , MM = np.min(np.array(gt_img)), np.max(np.array(gt_img))\n",
    "        image = (np.array(gt_img) - mm) / (MM - mm) * 255\n",
    "        image = np.array(image,dtype = np.float32)\n",
    "\n",
    "        # Read in the mask\n",
    "        mask = np.array(label_img)\n",
    "        \n",
    "        # Data augmentation \n",
    "        if self._transform is not None:\n",
    "            augmented = self._transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self._filename_slices)\n",
    "\n",
    "# Create Dataset and loaded images for classification models training\n",
    "class ClassDataset(Dataset):\n",
    "    def __init__(self, filename_slices, transform):\n",
    "        \"\"\"\n",
    "        Initialized\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._filename_slices = filename_slices \n",
    "        self._transform = transform    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Read in the image\n",
    "        if len(self._filename_slices) == 1:\n",
    "            label_img = self._filename_slices[index][1]\n",
    "            gt_img = self._filename_slices[index][0]\n",
    "            gt_path = self._filename_slices[index][2]\n",
    "            labelvalue = self._filename_slices[index][3]\n",
    "        \n",
    "        else:\n",
    "            label_img = self._filename_slices[index][1]\n",
    "            gt_img = self._filename_slices[index][0]\n",
    "            gt_path = self._filename_slices[index][2]\n",
    "            labelvalue = self._filename_slices[index][3]\n",
    "            \n",
    "        # Data augmentation \n",
    "        if self._transform is not None:\n",
    "            augmented = self._transform(image=np.array(label_img))\n",
    "            label_img = augmented['image']\n",
    "            augmented1 = self._transform(image=np.array(gt_img))\n",
    "            gt_img = augmented1['image']\n",
    "        \n",
    "        return gt_img, label_img, gt_path, labelvalue\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self._filename_slices)\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    # Convert the input to a numpy array if it is a torch Tensor\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true = y_true.cpu().detach().numpy()\n",
    "    \n",
    "    if isinstance(y_pred, torch.Tensor):\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "    \n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    smooth = 0.0001\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def read_slices(all_data):\n",
    "    filename_slices = []\n",
    "    for idx, fn_mask in enumerate(all_data):\n",
    "        label_path = Path(fn_mask)\n",
    "        label_path = str(label_path) \n",
    "\n",
    "        label_img = (Image.open(Path(label_path[5:len((label_path))])))\n",
    "        label_img = np.array(label_img)\n",
    "        label_img[label_img<128] = 0\n",
    "        label_img[label_img>=128] = 1\n",
    "        \n",
    "        img_need = label_path[21:len(str(fn_mask))]\n",
    "        \n",
    "        gt_path = '240618_data_3ch/'+img_need\n",
    "        gt_img = np.array(Image.open(gt_path))\n",
    "        label_img = np.array(label_img)\n",
    "\n",
    "        filename_slices += [(label_path,label_img,gt_path,gt_img,idx)]\n",
    "    return filename_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ck = torch.load('filenames.pth')\n",
    "tt = file_ck['tt']\n",
    "test_filenames = file_ck['testfiles']\n",
    "train_filenames, val_filenames = train_test_split(tt, test_size = 0.3) \n",
    "print(\"Number of images (Before Image Augmentation) in Training set : \",len(train_filenames),\"  Number of images in Testing set : \",len(test_filenames))\n",
    "print(\"Number of images (Before Image Augmentation) in Validation set : \",len(val_filenames))\n",
    "\n",
    "label_all = pd.read_csv('test_1ch.csv',header = None)\n",
    "labels_files = label_all[0]\n",
    "labels_co = label_all[1]\n",
    "\n",
    "filename_slices = []\n",
    "for i in range(len(test_filenames)):\n",
    "    str_filename = str(test_filenames[i])\n",
    "    str_filename = str_filename[5:len(str_filename)]\n",
    "    \n",
    "    label_path = str_filename\n",
    "    labels = labels_co[labels_files[labels_files == str_filename].index]-1\n",
    "    \n",
    "    label_img1 = Image.open(label_path)\n",
    "    label_img = np.array(label_img1)\n",
    "    label_img1.close()\n",
    "    label_img[label_img<128] = 0\n",
    "    label_img[label_img>=128] = 255\n",
    "    \n",
    "    img_need = label_path[17:len(str(label_path))]\n",
    "    gt_path = '240618_data_3ch/'+img_need\n",
    "    gt_img1 = Image.open(gt_path)\n",
    "    gt_img = np.array(gt_img1)\n",
    "    gt_img1.close()\n",
    "    filename_slices += [(gt_img,label_img,gt_path,labels.values[0])]\n",
    "\n",
    "train_filenamesnew = []\n",
    "val_filenamesnew = []\n",
    "\n",
    "for i in range(len(train_filenames)):\n",
    "    str_filename = str(train_filenames[i])\n",
    "    str_filename = str_filename[5:len(str_filename)]\n",
    "    train_filenamesnew.append(str_filename)\n",
    "    \n",
    "for i in range(len(val_filenames)):\n",
    "    str_filename = str(val_filenames[i])\n",
    "    str_filename = str_filename[5:len(str_filename)]\n",
    "    val_filenamesnew.append(str_filename)\n",
    "    \n",
    "trainfiles = []\n",
    "for i in range(len(train_filenames)):\n",
    "    str_filename = str(train_filenames[i])\n",
    "    str_filename = str_filename[5:len(str_filename)]\n",
    "    \n",
    "    label_path = str_filename\n",
    "    labels = labels_co[labels_files[labels_files == str_filename].index]-1\n",
    "    \n",
    "    label_img1 = Image.open(label_path)\n",
    "    label_img = np.array(label_img1)\n",
    "    label_img1.close()\n",
    "    label_img[label_img<128] = 0\n",
    "    label_img[label_img>=128] = 255\n",
    "    \n",
    "    img_need = label_path[17:len(str(label_path))]\n",
    "    gt_path = '240618_data_3ch/'+img_need\n",
    "    gt_img1 = Image.open(gt_path)\n",
    "    gt_img = np.array(gt_img1)\n",
    "    gt_img1.close()\n",
    "    trainfiles += [(gt_img,label_img,gt_path,labels.values[0])]\n",
    "    \n",
    "valfiles = []\n",
    "for i in range(len(val_filenames)):\n",
    "    str_filename = str(val_filenames[i])\n",
    "    str_filename = str_filename[5:len(str_filename)]\n",
    "    \n",
    "    label_path = str_filename\n",
    "    labels = labels_co[labels_files[labels_files == str_filename].index]-1\n",
    "    \n",
    "    label_img1 = Image.open(label_path)\n",
    "    label_img = np.array(label_img1)\n",
    "    label_img1.close()\n",
    "    label_img[label_img<128] = 0\n",
    "    label_img[label_img>=128] = 255\n",
    "    \n",
    "    img_need = label_path[17:len(str(label_path))]\n",
    "    gt_path = '240618_data_3ch/'+img_need\n",
    "    gt_img1 = Image.open(gt_path)\n",
    "    gt_img = np.array(gt_img1)\n",
    "    gt_img1.close()\n",
    "    valfiles += [(gt_img,label_img,gt_path,labels.values[0])]\n",
    "\n",
    "\n",
    "train_file_labels = read_slices(train_filenames)\n",
    "val_file_labels = read_slices(val_filenames)\n",
    "test_file_labels = read_slices(test_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class contracting(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(3, 64, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(64, 64, 3, stride=1, padding=1), nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(64, 128, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(128, 128, 3, stride=1, padding=1), nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(128, 256, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(256, 256, 3, stride=1, padding=1), nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(256, 512, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(512, 512, 3, stride=1, padding=1), nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(nn.Conv2d(512, 1024, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(1024, 1024, 3, stride=1, padding=1), nn.ReLU())\n",
    "        self.down_sample = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X1 = self.layer1(X)\n",
    "        X2 = self.layer2(self.down_sample(X1))\n",
    "        X3 = self.layer3(self.down_sample(X2))\n",
    "        X4 = self.layer4(self.down_sample(X3))\n",
    "        X5 = self.layer5(self.down_sample(X4))\n",
    "        return X5, X4, X3, X2, X1\n",
    "\n",
    "class expansive(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Conv2d(64, 2, 3, stride=1, padding=1)\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(128, 64, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(64, 64, 3, stride=1, padding=1), nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(256, 128, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(128, 128, 3, stride=1, padding=1), nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(512, 256, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(256, 256, 3, stride=1, padding=1), nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(nn.Conv2d(1024, 512, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(512, 512, 3, stride=1, padding=1), nn.ReLU())\n",
    "        self.up_sample_54 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.up_sample_43 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.up_sample_32 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.up_sample_21 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "\n",
    "    def forward(self, X5, X4, X3, X2, X1):\n",
    "        X = self.up_sample_54(X5)\n",
    "        X4 = torch.cat([X, X4], dim=1)\n",
    "        X4 = self.layer5(X4)\n",
    "\n",
    "        X = self.up_sample_43(X4)\n",
    "        X3 = torch.cat([X, X3], dim=1)\n",
    "        X3 = self.layer4(X3)\n",
    "\n",
    "        X = self.up_sample_32(X3)\n",
    "        X2 = torch.cat([X, X2], dim=1)\n",
    "        X2 = self.layer3(X2)\n",
    "\n",
    "        X = self.up_sample_21(X2)\n",
    "        X1 = torch.cat([X, X1], dim=1)\n",
    "        X1 = self.layer2(X1)\n",
    "\n",
    "        X = self.layer1(X1)\n",
    "\n",
    "        return X\n",
    "\n",
    "class unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.down = contracting()\n",
    "        self.up = expansive()\n",
    "\n",
    "    def forward(self, X):\n",
    "        X5, X4, X3, X2, X1 = self.down(X)\n",
    "        X = self.up(X5, X4, X3, X2, X1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MnUV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hswish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        out = x * F.relu6(x + 3, inplace=True) / 6\n",
    "        return out\n",
    "\n",
    "class hsigmoid(nn.Module):\n",
    "    def forward(self, x):\n",
    "        out = F.relu6(x + 3, inplace=True) / 6\n",
    "        return out\n",
    "\n",
    "class SeModule(nn.Module):\n",
    "    def __init__(self, in_size, reduction=4):\n",
    "        super(SeModule, self).__init__()\n",
    "        expand_size =  max(in_size // reduction, 8)\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_size, expand_size, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(expand_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(expand_size, in_size, kernel_size=1, bias=False),\n",
    "            nn.Hardsigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.se(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, kernel_size, in_size, expand_size, out_size, act, se, stride):\n",
    "        super(Block, self).__init__()\n",
    "        self.stride = stride\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_size, expand_size, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(expand_size)\n",
    "        self.act1 = act(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(expand_size, expand_size, kernel_size=kernel_size, stride=stride, padding=kernel_size//2, groups=expand_size, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(expand_size)\n",
    "        self.act2 = act(inplace=True)\n",
    "        self.se = SeModule(expand_size) if se else nn.Identity()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(expand_size, out_size, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_size)\n",
    "        self.act3 = act(inplace=True)\n",
    "\n",
    "        self.skip = None\n",
    "        if stride == 1 and in_size != out_size:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_size, out_size, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_size)\n",
    "            )\n",
    "\n",
    "        if stride == 2 and in_size != out_size:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_size, out_channels=in_size, kernel_size=3, groups=in_size, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(in_size),\n",
    "                nn.Conv2d(in_size, out_size, kernel_size=1, bias=True),\n",
    "                nn.BatchNorm2d(out_size)\n",
    "            )\n",
    "\n",
    "        if stride == 2 and in_size == out_size:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_size, out_channels=out_size, kernel_size=3, groups=in_size, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_size)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip = x\n",
    "        out = self.act1(self.bn1(self.conv1(x)))\n",
    "        out = self.act2(self.bn2(self.conv2(out)))\n",
    "        out = self.se(out)\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        \n",
    "        if self.skip is not None:\n",
    "            skip = self.skip(skip)\n",
    "        return self.act3(out + skip)\n",
    "\n",
    "class expansive1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.up_sample_54 = nn.ConvTranspose2d(960, 484, 2, stride=2)\n",
    "        self.layer5 = nn.Sequential(nn.Conv2d(960, 484, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(484, 484, 3, stride=1, padding=1), nn.ReLU())\n",
    "        \n",
    "        self.up_sample_43 = nn.ConvTranspose2d(484, 420, 2, stride=2)\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(484, 420, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(420, 420, 3, stride=1, padding=1), nn.ReLU())\n",
    "        \n",
    "        self.up_sample_32 = nn.ConvTranspose2d(420, 404, 2, stride=2)\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(420, 404, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(404, 404, 3, stride=1, padding=1), nn.ReLU())\n",
    "        \n",
    "        self.up_sample_21 = nn.ConvTranspose2d(404, 401, 2, stride=2)\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(404, 401, 3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(401, 401, 3, stride=1, padding=1), nn.ReLU())\n",
    "        self.layer1 = nn.Conv2d(401, 2, 3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, X5, X4, X3, X2, X1):\n",
    "\n",
    "        X = self.up_sample_54(X5)\n",
    "        X4 = torch.cat([X, X4], dim=1)\n",
    "        X4 = self.layer5(X4)\n",
    "        X = self.up_sample_43(X4)\n",
    "        X3 = torch.cat([X, X3], dim=1)\n",
    "        X3 = self.layer4(X3)\n",
    "        X = self.up_sample_32(X3)\n",
    "        X2 = torch.cat([X, X2], dim=1)\n",
    "        X2 = self.layer3(X2)\n",
    "        X = self.up_sample_21(X2)\n",
    "        X1 = torch.cat([X, X1], dim=1)\n",
    "        X1 = self.layer2(X1)\n",
    "        X = self.layer1(X1)\n",
    "\n",
    "        return X\n",
    "\n",
    "class MnUV3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnUV3, self).__init__()\n",
    "        # Encoding\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.hs1 = nn.Hardswish(inplace=True)\n",
    "        self.bneck1 = Block(3, 16, 64, 64, nn.ReLU, False, 2)\n",
    "        self.bneck2 = Block(5, 64, 672, 476, nn.Hardswish, True, 2)\n",
    "        self.conv2 = nn.Conv2d(476, 960, kernel_size=1, stride=2, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(960)\n",
    "        self.hs2 = nn.Hardswish(inplace=True)\n",
    "        self.linear4 = nn.Linear(960, 2)\n",
    "        # Decoding\n",
    "        self.up = expansive1()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding\n",
    "        x1 = self.hs1(self.bn1(self.conv1(x))) \n",
    "        xa1 = self.bneck1(x1) \n",
    "        xa2 = self.bneck2(xa1)\n",
    "        x3 = (self.hs2(self.bn2(self.conv2(xa2))))  \n",
    "\n",
    "        # Decoding\n",
    "        x = self.up(x3,xa2,xa1,x1,x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClassNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2dout(hin,win,conv,pool=2):\n",
    "    k=conv.kernel_size\n",
    "    s=conv.stride\n",
    "    p=conv.padding\n",
    "    d=conv.dilation\n",
    "    ho=np.floor((hin+2*p[0]-d[0]*(k[0]-1)-1)/s[0]+1)\n",
    "    wo=np.floor((win+2*p[1]-d[1]*(k[1]-1)-1)/s[1]+1)\n",
    "    \n",
    "    if pool:\n",
    "        ho = ho/pool\n",
    "        wo = wo/pool\n",
    "    return int(ho),int(wo)\n",
    "\n",
    "class Network(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        # Convolution Layers\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3)\n",
    "        h,w = conv2dout(256,256,self.conv1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        h,w = conv2dout(h,w,self.conv2)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3)\n",
    "        h,w = conv2dout(h,w,self.conv2)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3)\n",
    "        h,w = conv2dout(h,w,self.conv4)\n",
    "        self.num_flatten=512*h*w\n",
    "        self.fc1 = nn.Linear(self.num_flatten, 50)\n",
    "        self.fc2 = nn.Linear(50, 2)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.conv1(X)); \n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv3(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv4(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, self.num_flatten)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X=F.dropout(X, 0.1)\n",
    "        X = self.fc2(X)\n",
    "        X = F.softmax(X,dim = 1)\n",
    "        \n",
    "        return X[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation Models Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform_seg = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=0.0, std=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Rotate(limit=10, p=0.5),\n",
    "        \n",
    "        # A.RandomBrightnessContrast(p=0.5),\n",
    "        # A.Defocus(p = 0.5),\n",
    "        # A.Downscale(scale_min = 0.3,scale_max = 0.55,p = 0.5,interpolation = cv2.INTER_CUBIC),\n",
    "        # A.GaussNoise(var_limit=0.4,p = 0.5),\n",
    "\n",
    "        A.Resize(256, 256),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform_seg = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=0.0, std=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Rotate(limit=10, p=0.5),\n",
    "        \n",
    "        # A.RandomBrightnessContrast(p=0.5),\n",
    "        # A.Defocus(p = 0.5),\n",
    "        # A.Downscale(scale_min = 0.3,scale_max = 0.55,p = 0.5,interpolation = cv2.INTER_CUBIC),\n",
    "        # A.GaussNoise(var_limit=0.4,p = 0.5),\n",
    "\n",
    "        A.Resize(256, 256),\n",
    "        ToTensorV2(),]\n",
    ")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "epochs = 300\n",
    "\n",
    "lrnew = 1e-4\n",
    "batch_size = 16\n",
    "\n",
    "for trial in range(10):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    resume = 0 # 1: from (half) trained models, 0: start a new training\n",
    "    model = MnUV3() # model = unet()\n",
    "    model.to(device)\n",
    "    print(f'Device is {device}')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lrnew)\n",
    "    train_accuracy = np.zeros(epochs)\n",
    "    train_loss = np.zeros(epochs)\n",
    "    validation_accuracy = np.zeros(epochs)\n",
    "    validation_loss = np.zeros(epochs)\n",
    "\n",
    "    if resume == 0:\n",
    "        now = datetime.now()\n",
    "        current_time = date(now.year, now.month,now.day).strftime('%y%m%d')\n",
    "        current_new = time(now.hour, now.minute).strftime('%H%M')\n",
    "        foldername = os.getcwd() +'/'+ current_time+'_'+current_new+'_epoch'+str(epochs)+'_batch'+str(batch_size)+'_img'+'_adam'+str(lrnew)+'_v3_train_no_test_no/'\n",
    "        if os.path.isdir(foldername) == False:\n",
    "            os.mkdir(foldername)\n",
    "        print(foldername)\n",
    "        start_epoch = 1\n",
    "\n",
    "    else:\n",
    "        foldername = checkpoint_fpath[0:84]\n",
    "        checkpoint = torch.load(checkpoint_fpath)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        train_accuracy[0:len(checkpoint['train_acc'])] = checkpoint['train_acc']\n",
    "        train_loss[0:len(checkpoint['train_loss'])] = checkpoint['train_loss']\n",
    "        validation_accuracy[0:len(checkpoint['val_acc'])] = checkpoint['val_acc']\n",
    "        validation_loss[0:len(checkpoint['val_loss'])] = checkpoint['val_loss']\n",
    "\n",
    "    # Create the datsets and dataloaders for every subset \n",
    "    train_dataset = SegDataset(train_file_labels, train_transform_seg)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=0, shuffle=True) \n",
    "    val_dataset = SegDataset(val_file_labels, test_transform_seg)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=0, shuffle=False) \n",
    "\n",
    "    # Create the loss function\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        # Training Loop\n",
    "        print('='*30)\n",
    "        print('Epoch {} / {}'.format(epoch, epochs))\n",
    "        \n",
    "        # Set variables\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        epoch_counter = 0\n",
    "        model.train()\n",
    "\n",
    "        # Batch Training Loop (Loop over the batches)\n",
    "        for index, (X, Y) in enumerate(train_dataloader):\n",
    "            if device is not None:\n",
    "                X = X.to(device)\n",
    "                Y = Y.to(device)\n",
    "\n",
    "            # Call the model (image to mask)\n",
    "            R = model(X)\n",
    "            # Compute the loss\n",
    "            L = loss(R, Y.long())\n",
    "            # Do PyTorch stuff - Training \n",
    "            optimizer.zero_grad()\n",
    "            L.backward()\n",
    "            optimizer.step()\n",
    "            pred = R.data.max(1)[1]\n",
    "            \n",
    "            # Analyze the accuracy of the batch \n",
    "            epoch_accuracy += dice_coef(pred, Y) * X.shape[0]\n",
    "            epoch_loss += L.data.item() * X.shape[0]\n",
    "            print(f'\\tBatch {index} loss {L.data.item():3.3f}')\n",
    "            epoch_counter += X.shape[0]\n",
    "    \n",
    "        # Epoch Train Loss\n",
    "        train_accuracy[epoch] = epoch_accuracy/epoch_counter\n",
    "        train_loss[epoch] = epoch_loss/epoch_counter\n",
    "        print(f\"Loss: {train_loss[epoch]:3.3f}, Accuracy: {train_accuracy[epoch]:3.3f}\")\n",
    "        \n",
    "        # Validation Loop \n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        epoch_counter = 0\n",
    "        model.eval()\n",
    "        \n",
    "        # Batch Validation Loop (Loop over the batches)\n",
    "        with torch.no_grad():\n",
    "            for index, (X, Y) in enumerate(val_dataloader):\n",
    "                if device is not None:\n",
    "                    X = X.to(device)\n",
    "                    Y = Y.to(device)\n",
    "\n",
    "                # Call the model (image to mask)\n",
    "                R = model(X)\n",
    "\n",
    "                # Compute the loss\n",
    "                L = loss(R, Y.long())\n",
    "                pred = R.data.max(1)[1]\n",
    "\n",
    "                # Analyze the accuracy of the batch \n",
    "                epoch_accuracy += dice_coef(pred, Y) * X.shape[0]\n",
    "                epoch_loss += L.data.item() * X.shape[0]\n",
    "                print('\\tBatch ', index, L.data.item())\n",
    "                epoch_counter += X.shape[0]\n",
    "\n",
    "        # Epoch Train Loss\n",
    "        validation_accuracy[epoch] = epoch_accuracy/epoch_counter\n",
    "        validation_loss[epoch] = epoch_loss/epoch_counter\n",
    "        print(f\"Validation Loss: {validation_loss[epoch]:3.3f}, Accuracy: {validation_accuracy[epoch]:3.3f}\")\n",
    "\n",
    "        if epoch % 10 == 9 and epoch > 70:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict()\n",
    "                }\n",
    "            torch.save(checkpoint, foldername+str(epoch)+'.pth')\n",
    "        if epoch == 299:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'train_acc': train_accuracy,\n",
    "                'train_loss': train_loss,\n",
    "                'val_acc': validation_accuracy,\n",
    "                'val_loss': validation_loss\n",
    "                }\n",
    "            torch.save(checkpoint, foldername+str(epoch)+'.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform_class = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=0.0, std=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Rotate(limit=10, p=0.5),\n",
    "\n",
    "        A.Resize(256, 256),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform_class = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=0.0, std=1.0),\n",
    "        A.Resize(256, 256),\n",
    "        ToTensorV2()]\n",
    ")\n",
    "\n",
    "for trial in range(10):\n",
    "    torch.cuda.empty_cache()\n",
    "    epochs = 300\n",
    "    lrnew = 1e-3\n",
    "    batch_size = 128\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    resume = 0\n",
    "    model = Network()\n",
    "\n",
    "    model.to(device)\n",
    "    print(f'Device is {device}')\n",
    "    optimizer1 = torch.optim.Adam(model.parameters(), lr=lrnew)\n",
    "    optimizer2 = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    train_accuracy = np.zeros(epochs)\n",
    "    train_loss = np.zeros(epochs)\n",
    "    validation_accuracy = np.zeros(epochs)\n",
    "    validation_loss = np.zeros(epochs)\n",
    "\n",
    "    if resume == 0:\n",
    "        now = datetime.now()\n",
    "        current_time = date(now.year, now.month,now.day).strftime('%y%m%d')\n",
    "        current_new = time(now.hour, now.minute).strftime('%H%M')\n",
    "        foldername = os.getcwd() + '/'+ current_time+'_'+current_new+'_epoch'+str(epochs)+'_batch'+str(batch_size)+'_img'+'_adam'+str(lrnew)+'_classify/'\n",
    "        if os.path.isdir(foldername) == False:\n",
    "            os.mkdir(foldername)\n",
    "        print(foldername)\n",
    "        start_epoch = 1\n",
    "\n",
    "    train_dataset = ClassDataset(trainfiles,train_transform_class)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=0, shuffle=True) \n",
    "    val_dataset = ClassDataset(valfiles, test_transform_class)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=0, shuffle=False) \n",
    "\n",
    "    # Create the loss function\n",
    "    loss = torch.nn.BCELoss()\n",
    "\n",
    "    for epoch in range(start_epoch,epochs):\n",
    "        if epoch > 20:\n",
    "            op = optimizer2\n",
    "        else:\n",
    "            op = optimizer1\n",
    "        # Training Loop\n",
    "        print('='*30)\n",
    "        print('Epoch {} / {}'.format(epoch, epochs))\n",
    "        \n",
    "        # Set variables\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        epoch_counter = 0\n",
    "        model.train()\n",
    "\n",
    "        # Batch Training Loop \n",
    "        for index, (a,X,path, Y) in enumerate(train_dataloader):\n",
    "            if device is not None:\n",
    "                X = X.to(device)\n",
    "                Y = Y.to(device)\n",
    "\n",
    "            # Call the model (image to mask)\n",
    "            R = model(X)\n",
    "            # Compute the loss\n",
    "            L = loss(R.float(), Y.float())\n",
    "            # Do PyTorch stuff - Training \n",
    "            op.zero_grad()\n",
    "            L.backward()\n",
    "            op.step()\n",
    "            \n",
    "            pred = R.data\n",
    "            # Analyze the accuracy of the batch \n",
    "            epoch_accuracy += np.array(abs(Y-R.data).cpu()).sum()\n",
    "            epoch_loss += L.data.item() * X.shape[0]\n",
    "            print(f'\\tBatch {index} loss {L.data.item():3.3f}')\n",
    "            epoch_counter += X.shape[0]\n",
    "\n",
    "        # Epoch Train Loss\n",
    "        train_accuracy[epoch] = 1-epoch_accuracy/epoch_counter\n",
    "        train_loss[epoch] = epoch_loss/epoch_counter\n",
    "        print(f\"Loss: {train_loss[epoch]:3.3f}, Accuracy: {train_accuracy[epoch]:3.3f}\")\n",
    "        \n",
    "        # Validation Loop \n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        epoch_counter = 0\n",
    "        model.eval()\n",
    "        \n",
    "        # Batch Validation Loop \n",
    "        with torch.no_grad():\n",
    "            for index, (a,X,path, Y) in enumerate(val_dataloader):\n",
    "                if device is not None:\n",
    "                    X = X.to(device)\n",
    "                    Y = Y.to(device)\n",
    "\n",
    "                # Call the model \n",
    "                R = model(X)\n",
    "\n",
    "                # Compute the loss\n",
    "                L = loss(R.float(), Y.float())\n",
    "                pred = R.data\n",
    "\n",
    "                # Accuracy of the batch \n",
    "                epoch_accuracy += np.array(abs(Y-R.data).cpu()).sum()\n",
    "                epoch_loss += L.data.item() * X.shape[0]\n",
    "                print('\\tBatch ', index, L.data.item())\n",
    "\n",
    "                epoch_counter += X.shape[0]\n",
    "\n",
    "        # Epoch Train Loss\n",
    "        validation_accuracy[epoch] = 1-epoch_accuracy/epoch_counter\n",
    "        validation_loss[epoch] = epoch_loss/epoch_counter\n",
    "        print(f\"Validation Loss: {validation_loss[epoch]:3.3f}, Accuracy: {validation_accuracy[epoch]:3.3f}\")\n",
    "\n",
    "        if epoch % 10 == 9:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': op.state_dict(),\n",
    "                'train_acc': train_accuracy,\n",
    "                'train_loss': train_loss,\n",
    "                'val_acc': validation_accuracy,\n",
    "                'val_loss': validation_loss\n",
    "                }\n",
    "            torch.save(checkpoint, foldername+str(epoch)+'.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
